{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "# import pandas as pd \n",
    "import requests\n",
    "\"\"\"\n",
    "# Instalar automaticamente chromedriver\n",
    "# Driver Selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Para esperar\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "# para esperar que aparezca un elemento\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from logic.tools import iniciar_chrome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tragedia en Bahía Blanca\n",
      "Primera foto de gestión Milei-Kicillof: detalles de una reunión con gusto a poco\n",
      "El Presidente y el gobernador de PBA compartieron una reunión con el Comité de Crisis en Bahía Blanca tras la devastación y las muertes causadas por el temporal.   \n"
     ]
    }
   ],
   "source": [
    "# DESTAPE TEST\n",
    "driver = iniciar_chrome()\n",
    "url=\"https://www.eldestapeweb.com\"\n",
    "driver.get(url)\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "elemento = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.data\")))\n",
    "elementos = driver.find_elements(By.CSS_SELECTOR,\"div.data\")\n",
    "titulo_nota = elemento.text\n",
    "print(titulo_nota)\n",
    "\n",
    "notas ={}\n",
    "for element in elementos:\n",
    "    titulo = element.find_element(By.CSS_SELECTOR,\"div.titulo\").text\n",
    "    \n",
    "    # Encontrar el elemento <a> por su selector CSS\n",
    "    elemento_enlace = element.find_element(By.CSS_SELECTOR, 'div.titulo h2 a')\n",
    "\n",
    "    # Obtener el contenido del atributo href\n",
    "    valor_href = elemento_enlace.get_attribute(\"href\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    if titulo in notas:\n",
    "        # Si la clave ya existe en el diccionario, agregamos el nuevo valor a la lista existente\n",
    "        notas[titulo].append(valor_href)\n",
    "    else:\n",
    "        # Si la clave no existe, creamos una nueva lista con el valor\n",
    "        notas[titulo] = [valor_href]\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.eldestapeweb.com\"\n",
    "consulta = requests.get(url)\n",
    "soup = BeautifulSoup(consulta.content,'html')\n",
    "divs = soup.find_all(\"div\", class_=\"data\")\n",
    "notas_bs={}\n",
    "\n",
    "for div in divs:\n",
    "    titulo = div.find(\"div\",class_=\"titulo\").a.contents[0]\n",
    "    valor_href = url+div.find(\"div\",class_=\"titulo\").a[\"href\"]\n",
    "    \n",
    "    if titulo not in notas_bs:\n",
    "        # Si la clave no existe, creamos una nueva lista con el valor\n",
    "        notas_bs[titulo] = [valor_href]\n",
    "    else:\n",
    "        # Si la clave ya existe en el diccionario, agregamos el nuevo valor a la lista existente\n",
    "        notas_bs[titulo].append(valor_href)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(notas) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(notas_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for div in divs:\n",
    "    print(f\"{div.find(\"div\",class_=\"titulo\").a.contents[0]}: {url+div.find(\"div\",class_=\"titulo\").a[\"href\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtener la url de cada elemento del diccionario (de cada nota)\n",
    "for elemento in notas_bs:\n",
    "    print(notas_bs[elemento][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacion de locale para modificar idioma de fecha\n",
    "import locale\n",
    "from datetime import datetime\n",
    "\n",
    "# Importacion unicodedata para normalizar texto\n",
    "import unicodedata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_info_nota_destape(url):\n",
    "    nota = requests.get(url)\n",
    "    soup = BeautifulSoup(nota.content,'html')\n",
    "    resumen = extraer_resumen_nota_destape(soup)\n",
    "    fecha = extraer_fecha_nota_destape(soup)\n",
    "    return (resumen, fecha)\n",
    "\n",
    "def extraer_resumen_nota_destape(soup):\n",
    "    resumen = soup.find(\"h2\", class_=\"intro\").contents[0]\n",
    "    resumen_normalizado = unicodedata.normalize(\"NFKD\",resumen)\n",
    "    return resumen_normalizado \n",
    "\n",
    "def extraer_fecha_nota_destape(soup):\n",
    "    # Setea la variable LC_ALL al conjunto de código UTF-8 con descripción español España \n",
    "    locale.setlocale(locale.LC_ALL,'es_ES.UTF-8')\n",
    "\n",
    "    # obtencion fecha y hora de nota\n",
    "    # Obtenemos el div padre\n",
    "    fecha = soup.find(\"div\",class_=\"fecha\")\n",
    "    fecha_dia = fecha.span.next\n",
    "    hora = fecha.find(\"span\",class_=\"hora\").next\n",
    "\n",
    "    # concatenacion de fecha y hora\n",
    "    hora_fecha = fecha_dia + hora\n",
    "\n",
    "    # Transformación de str a datetime\n",
    "    fecha_dt = datetime.strptime(hora_fecha,r\"%d DE %B, %Y | %H.%M\")\n",
    "\n",
    "    # Setea la variable LC_ALL al conjunto de código UTF-8 con descripción ingles Estados Unidos\n",
    "    locale.setlocale(locale.LC_ALL,'en_US.UTF-8')\n",
    "    return fecha_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('El Presidente y el gobernador de la provincia de Buenos Aires compartieron una reunión con el Comité de Crisis en Bahía Blanca tras la devastación y las muertes causadas por el temporal. El primero no anunció recursos, el segundo le pidió al menos coordinar el despliegue de fuerzas federales. ', datetime.datetime(2023, 12, 17, 18, 7))\n"
     ]
    }
   ],
   "source": [
    "#nota = requests.get(\"https://www.eldestapeweb.com/politica/bahia-blanca/primera-foto-de-gestion-de-milei-y-kicillof-todos-los-detalles-de-una-reunion-con-gusto-a-poco-202312171870\")\n",
    "#soup = BeautifulSoup(nota.content,'html')\n",
    "\n",
    "print(extraer_info_nota_destape(\"https://www.eldestapeweb.com/politica/bahia-blanca/primera-foto-de-gestion-de-milei-y-kicillof-todos-los-detalles-de-una-reunion-con-gusto-a-poco-202312171870\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'17 de diciembre, 2023 | 18.07'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hora_fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#hora_dt = datetime.strptime(hora,r\" | %H.%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-17 18:07:00\n"
     ]
    }
   ],
   "source": [
    "print(fecha_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_s = \"17 DE DICIEMBRE, 2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-17 00:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fecha_dt = datetime.strptime(fecha_s,r\"%d DE %B, %Y\")\n",
    "print(fecha_dt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
